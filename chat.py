#UIæ¡†æ¶
import os
import streamlit as st
from rag import rag_chain
from dotenv import dotenv_values
from langchain_openai import ChatOpenAI
from langchain_community.llms import QianfanLLMEndpoint
#åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
config = dotenv_values(".env")

os.environ["QIANFAN_AK"] = "rYndCW8UyNrh7ZIxAmxG0w1X"
os.environ["QIANFAN_SK"] = "KovKWoaJeKYeIQwLgOUxFof5KI1ggTRq"

ERNIE4_llm = QianfanLLMEndpoint(model="ERNIE-4.0-8K", streaming=True)
Yi_llm = QianfanLLMEndpoint(model="Yi-34B-Chat", streaming=True)
Llama_llm = QianfanLLMEndpoint(model="Meta-Llama-3-8B", streaming=True)
ChatGLM_llm = QianfanLLMEndpoint(model="ChatGLM2-6B-32K", streaming=True)



#UIçš„æ ‡é¢˜
def chat_page():
    #UIç•Œé¢çš„è¾¹æ ï¼Œé€šè¿‡ä¸‹æ‹‰åˆ—è¡¨åˆ‡æ¢llmæ¨¡å‹
    with st.sidebar:
        pattern_list = [
            "å¤§æ¨¡å‹é—®ç­”",
            "åŒ»ç–—çŸ¥è¯†åº“é—®ç­”",
        ]

        model_list = [
            "æ–‡å¿ƒä¸€è¨€4.0",
            "ChatGLM-6B",
            "Llama3-8B",
            "Yi-34B",
        ]
        pattern = st.selectbox("å¯¹è¯æ¨¡å¼é€‰æ‹©ï¼š",
                             pattern_list,
                             index=0
                             )
        st.write('You selected:', pattern)

        model = st.selectbox("å¯¹è¯æ¨¡å‹é€‰æ‹©ï¼š",
                             model_list,
                             index=0
                             )
        st.write('You selected:', model)

    st.title("ğŸ¤– ClinicaBrainï¼šæ™ºèƒ½åŒ»ç–—å¤§è„‘")
    #èŠå¤©å†å²è®°å½•åˆå§‹åŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

     #èŠå¤©ç•Œé¢å±•ç¤ºå†å²èŠå¤©
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
             st.markdown(message["content"])

    if pattern == "å¤§æ¨¡å‹é—®ç­”":
        if model == "æ–‡å¿ƒä¸€è¨€4.0":
            llm = ERNIE4_llm
        elif model == "ChatGLM-6B":
            llm = ChatGLM_llm
        elif model == "Llama3-8B":
            llm = Llama_llm
        elif model == "Yi-34B":
            llm = Yi_llm
    elif  pattern == "åŒ»ç–—çŸ¥è¯†åº“é—®ç­”":
        if model == "æ–‡å¿ƒä¸€è¨€4.0":
            llm = rag_chain(ERNIE4_llm)
        elif model == "ChatGLM-6B":
            llm = rag_chain(ChatGLM_llm)
        elif model == "Llama3-8B":
            llm = rag_chain(Llama_llm)
        elif model == "Yi-34B":
            llm = rag_chain(Yi_llm)

    if chat_input := st.chat_input("What is up?"):
        st.chat_message("user").markdown(chat_input)
        # å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°èŠå¤©è®°å½•
        st.session_state.messages.append({"role": "user", "content": chat_input})
        with st.chat_message("assistant"):
            #ä»¥æµå¼è¾“å‡ºçš„æ–¹å¼è°ƒç”¨llmçš„apiï¼Œå¹¶åœ¨UIç•Œé¢æ˜¾ç¤º
            response = st.write_stream(
                llm.stream(chat_input))
        # å°†å¤§æ¨¡å‹çš„æ¶ˆæ¯æ·»åŠ åˆ°èŠå¤©è®°å½•
        st.session_state.messages.append({"role": "assistant", "content": response})



