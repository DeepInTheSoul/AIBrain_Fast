import os
import streamlit as st
from dotenv import dotenv_values
from langchain_community.embeddings.baidu_qianfan_endpoint import QianfanEmbeddingsEndpoint
from langchain_community.llms.baidu_qianfan_endpoint import QianfanLLMEndpoint
from langchain_openai import ChatOpenAI
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import UnstructuredMarkdownLoader, PyPDFLoader, UnstructuredFileLoader
import codecs
import csv
config = dotenv_values(".env")


os.environ["QIANFAN_AK"] = "rYndCW8UyNrh7ZIxAmxG0w1X"
os.environ["QIANFAN_SK"] = "KovKWoaJeKYeIQwLgOUxFof5KI1ggTRq"
embeddings=QianfanEmbeddingsEndpoint(model='bge-large-zh')

def rag_page():
    st.title("ğŸ“šçŸ¥è¯†åº“ç®¡ç†")
    files = st.file_uploader("ä¸Šä¼ çŸ¥è¯†æ–‡ä»¶(ç›®å‰æ”¯æŒtxtã€pdfã€mdæ–‡ä»¶ï¼Œå»ºè®®å°†wordè½¬æ¢ä¸ºpdfæ–‡ä»¶)ï¼š")
    if files is not None:
        filepath = os.path.join('file', files.name)
        if filepath.lower().endswith(".csv"):
            num = 0
            with codecs.open(filepath) as f:
                new_json = []
                for row in csv.DictReader(f, skipinitialspace=True):
                    data = {}
                    data['question'] = row['ask']
                    data['answer'] = row['answer']
                    data_str = str(data)
                    num = num + 1
                    new_json.append(data_str)
                    if num > 1000:
                        break
                st.markdown("æ­£åœ¨æŠŠæ•°æ®ä¼ è‡³å‘é‡æ¨¡å‹ç¼–ç , è¯·è€å¿ƒç­‰å¾…, æš‚æ—¶å…ˆåˆ«åˆ‡æ¢ç•Œé¢")
                vector_db = Chroma.from_texts(new_json, embedding=embeddings, persist_directory="./chroma_db")
                vector_db.persist()
                st.markdown("---------------å·²å°†æ–‡ä»¶è£…è½½è¿›çŸ¥è¯†åº“ä¸­--------------------")
        else:
                docs = file_loader(files)
                konwlwdge_vec_store(docs)
                st.markdown("---------------å·²å°†æ–‡ä»¶è£…è½½è¿›çŸ¥è¯†åº“ä¸­--------------------")

def file_loader(file):
    filepath = os.path.join('file', file.name)
    with open(filepath, 'wb') as f:
        f.write(file.getbuffer())
    if filepath.lower().endswith(".md"):
        loader = UnstructuredMarkdownLoader(filepath)
        docs = loader.load()
    elif filepath.lower().endswith(".pdf"):
        loader = PyPDFLoader(filepath)
        docs = loader.load()
    elif filepath.lower().endswith(".txt"):
        loader = UnstructuredFileLoader(filepath,encoding='utf8')
        docs = loader.load()
    else:
        loader = UnstructuredFileLoader(filepath, mode="elements")
        docs = loader.load()
    return docs

def konwlwdge_vec_store(docs):

    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,
        chunk_overlap=100
    )

    splits = text_splitter.split_documents(docs)

    vector_db = Chroma.from_documents(documents=splits, embedding=embeddings, persist_directory="./chroma_db")
    vector_db.persist()



def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)



def rag_chain(llm):

    vector_db = Chroma(persist_directory="./chroma_db", embedding_function=embeddings)
    retriever = vector_db.as_retriever()

    # åŠ è½½ä¸€ä¸ªé¢„å…ˆå®šä¹‰çš„æç¤ºç”Ÿæˆå™¨ï¼Œç”¨äºç”Ÿæˆæ£€ç´¢é—®é¢˜ã€‚
    template = """åŸºäºä»¥ä¸‹å·²çŸ¥ä¿¡æ¯ï¼Œè¯·ä¸“ä¸šåœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
                ä¸è¦ä¹±å›ç­”ï¼Œå¦‚æœæ— æ³•ä»å·²çŸ¥ä¿¡æ¯ä¸­æ‰¾åˆ°ç­”æ¡ˆï¼Œè¯·è¯šå®åœ°å‘Šè¯‰ç”¨æˆ·ã€‚
                å·²çŸ¥å†…å®¹:   
                {context}
                é—®é¢˜:
                {question}"""

    prompt = ChatPromptTemplate.from_template(template)

    rag_chain = (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | prompt
        | llm
    )
    return rag_chain

